
import torch
import torch.nn.functional as F
import segmentation_models_pytorch as smp
import numpy as np
import cv2
from PIL import Image
import gradio as gr
import albumentations as A
from albumentations.pytorch import ToTensorV2

# Load the trained model
def load_model():
    model = smp.Unet(
        encoder_name="resnet34",
        encoder_weights=None,
        in_channels=3,
        classes=2,
        activation=None,
    )

    checkpoint = torch.load("deployment_model.pth", map_location="cpu")
    model.load_state_dict(checkpoint["model_state_dict"])
    model.eval()
    return model

model = load_model()

# Preprocessing transforms
val_transform = A.Compose([
    A.Resize(256, 256),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

def predict_pet_segmentation(image):
    """Main prediction function"""
    original_image = np.array(image)
    h, w = original_image.shape[:2]

    # Preprocess
    transformed = val_transform(image=original_image)
    image_tensor = transformed["image"].unsqueeze(0)

    # Predict
    with torch.no_grad():
        output = model(image_tensor)
        probs = F.softmax(output, dim=1)[0, 1]  # Pet class probabilities
        pred_mask = (probs > 0.5).float().cpu().numpy()

    # Resize back to original
    pred_mask_resized = cv2.resize(pred_mask, (w, h))

    # Create colorful overlay (green for pet)
    overlay = original_image.copy()
    overlay[pred_mask_resized == 1] = [0, 255, 0]  # Green overlay

    # Calculate accuracy
    accuracy = np.mean((pred_mask_resized > 0.5).astype(float))

    return original_image, (pred_mask_resized * 255).astype(np.uint8), overlay, f"ğŸ¯ Accuracy: {accuracy:.1%}"

# Create Gradio interface
with gr.Blocks(theme=gr.themes.Soft(), title="PetVision AI") as demo:
    gr.Markdown("""
    # ğŸ¾ PetVision AI - Smart Pet Segmentation
    **Upload a photo of your pet to see AI-powered segmentation!**
    *Powered by Deep Learning â€¢ 87.7% IoU Accuracy*
    """)

    with gr.Row():
        with gr.Column():
            input_image = gr.Image(label="ğŸ“· Upload Pet Photo", type="numpy")
            submit_btn = gr.Button("Analyze My Pet! ğŸ¶", variant="primary")

        with gr.Column():
            with gr.Row():
                original_output = gr.Image(label="Original Photo")
                mask_output = gr.Image(label="AI Segmentation Mask")
                overlay_output = gr.Image(label="Green Overlay")
            accuracy_text = gr.Textbox(label="Results", interactive=False)

    submit_btn.click(
        fn=predict_pet_segmentation,
        inputs=[input_image],
        outputs=[original_output, mask_output, overlay_output, accuracy_text]
    )

if __name__ == "__main__":
    demo.launch()
